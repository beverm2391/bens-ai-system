{
    "llm": {
        "model": {
            "input_tokens": 0.0001,
            "output_tokens": 0.0003,
            "unit": "per_1k_tokens"
        }
    }
} 